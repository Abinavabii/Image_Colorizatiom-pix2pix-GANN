{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xa_TM7JXNUc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, Conv2DTranspose, Flatten, Concatenate, Activation, LeakyReLU\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_addons.layers import SpectralNormalization, InstanceNormalization\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import ReLU\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clr_path = \"/content/drive/MyDrive/datas/color\"\n",
        "gry_path = \"/content/drive/MyDrive/datas/black\"\n",
        "\n",
        "\n",
        "clr_img_path = []\n",
        "\n",
        "for img_path in os.listdir(clr_path) :\n",
        "    clr_img_path.append(os.path.join(clr_path, img_path))\n",
        "\n",
        "gry_img_path = []\n",
        "\n",
        "for img_path in os.listdir(gry_path) :\n",
        "    gry_img_path.append(os.path.join(gry_path, img_path))\n",
        "\n",
        "clr_img_path.sort()\n",
        "gry_img_path.sort()\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in tqdm(range(5000), desc=\"Processing images\"):\n",
        "\n",
        "    img1 = cv2.cvtColor(cv2.imread(clr_img_path[i]), cv2.COLOR_BGR2RGB)\n",
        "    img2 = cv2.cvtColor(cv2.imread(gry_img_path[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    y.append(img_to_array(Image.fromarray(cv2.resize(img1,(128,128)))))\n",
        "    X.append(img_to_array(Image.fromarray(cv2.resize(img2,(128,128)))))\n",
        "\n",
        "clr_img_path = [os.path.join(clr_path, img_name) for img_name in os.listdir(clr_path)]\n",
        "gry_img_path = [os.path.join(gry_path, img_name) for img_name in os.listdir(gry_path)]"
      ],
      "metadata": {
        "id": "DbUl0TUkXbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "red_histograms = []\n",
        "green_histograms = []\n",
        "blue_histograms = []\n",
        "\n",
        "for i in range(5000):\n",
        "    img1 = cv2.cvtColor(cv2.imread(clr_img_path[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    red_hist = cv2.calcHist([img1], [0], None, [256], [0, 256])\n",
        "    green_hist = cv2.calcHist([img1], [1], None, [256], [0, 256])\n",
        "    blue_hist = cv2.calcHist([img1], [2], None, [256], [0, 256])\n",
        "\n",
        "    red_hist = red_hist / red_hist.sum()\n",
        "    green_hist = green_hist / green_hist.sum()\n",
        "    blue_hist = blue_hist / blue_hist.sum()\n",
        "\n",
        "    red_histograms.append(red_hist)\n",
        "    green_histograms.append(green_hist)\n",
        "    blue_histograms.append(blue_hist)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.fill_between(range(256), red_histograms[0].flatten(), color='red', alpha=0.5)\n",
        "plt.title('Red Channel Histogram')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.fill_between(range(256), green_histograms[0].flatten(), color='green', alpha=0.5)\n",
        "plt.title('Green Channel Histogram')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.fill_between(range(256), blue_histograms[0].flatten(), color='blue', alpha=0.5)\n",
        "plt.title('Blue Channel Histogram')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "num_images_to_display = 6\n",
        "\n",
        "for i in range(num_images_to_display):\n",
        "\n",
        "    clr_img = cv2.cvtColor(cv2.imread(clr_img_path[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    red_hist = cv2.calcHist([clr_img], [0], None, [256], [0, 256])\n",
        "    green_hist = cv2.calcHist([clr_img], [1], None, [256], [0, 256])\n",
        "    blue_hist = cv2.calcHist([clr_img], [2], None, [256], [0, 256])\n",
        "\n",
        "\n",
        "    red_hist = red_hist / red_hist.sum()\n",
        "    green_hist = green_hist / green_hist.sum()\n",
        "    blue_hist = blue_hist / blue_hist.sum()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    plt.subplot(2, 4, 1)\n",
        "    plt.imshow(clr_img)\n",
        "    plt.title('Color Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 4, 2)\n",
        "    plt.fill_between(range(256), red_hist.flatten(), color='red', alpha=0.5)\n",
        "    plt.title('Red Channel Histogram')\n",
        "    plt.xlabel('Pixel Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(2, 4, 3)\n",
        "    plt.fill_between(range(256), green_hist.flatten(), color='green', alpha=0.5)\n",
        "    plt.title('Green Channel Histogram')\n",
        "    plt.xlabel('Pixel Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(2, 4, 4)\n",
        "    plt.fill_between(range(256), blue_hist.flatten(), color='blue', alpha=0.5)\n",
        "    plt.title('Blue Channel Histogram')\n",
        "    plt.xlabel('Pixel Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "jk1nW7yYXpV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 40))\n",
        "\n",
        "num_samples = 20\n",
        "\n",
        "for i in range(num_samples):\n",
        "    x = np.random.randint(0, 3000)\n",
        "\n",
        "    plt.subplot(num_samples, 2, 2 * i + 1)\n",
        "    plt.imshow(X[x] / 255.0, cmap='gray')  # Use 'gray' colormap for grayscale images\n",
        "    plt.axis('off')\n",
        "    plt.title('Gray Image')\n",
        "\n",
        "    plt.subplot(num_samples, 2, 2 * i + 2)\n",
        "    plt.imshow(y[x] / 255.0)\n",
        "    plt.axis('off')\n",
        "    plt.title('Color Image')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1uVUhZUqX1OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X = (X/127.5) - 1\n",
        "y = (y/127.5) - 1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, shuffle = False)\n",
        "init = RandomNormal(mean = 0.0, stddev = 0.02)\n",
        "\n",
        "def d_block(x_in, fltr, strd, pad, bn, inorm):\n",
        "    x = Conv2D(fltr, (4, 4),\n",
        "               strides=strd,\n",
        "               padding=pad,\n",
        "               use_bias=False,\n",
        "               kernel_initializer=init)(x_in)\n",
        "\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "    if inorm:\n",
        "        x = InstanceNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    return x\n",
        "\n",
        "def u_block(x, skip, fltr, strd, pad, bn, inorm):\n",
        "    x = Conv2DTranspose(fltr, (4, 4),\n",
        "                        strides=strd,\n",
        "                        padding=pad,\n",
        "                        use_bias=False,\n",
        "                        kernel_initializer=init)(x)\n",
        "\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "    if inorm:\n",
        "        x = InstanceNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    conc_x = Concatenate()([x, skip])\n",
        "\n",
        "    return conc_x\n",
        "\n"
      ],
      "metadata": {
        "id": "hDLpEmCpX4Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_patchgan(image_shape):\n",
        "    input_gen = Input(shape=image_shape)\n",
        "    input_tar = Input(shape=image_shape)\n",
        "    combined_inputs = Concatenate()([input_gen, input_tar])\n",
        "\n",
        "    x64 = d_block(combined_inputs, 64, 2, 'same', False, False)\n",
        "    x128 = d_block(x64, 128, 2, 'same', False, True)\n",
        "    x256 = d_block(x128, 256, 2, 'same', True, False)\n",
        "\n",
        "    padded_x256 = ZeroPadding2D()(x256)\n",
        "    x512 = d_block(padded_x256, 512, 1, 'valid', True, False)\n",
        "\n",
        "    padded_x512 = ZeroPadding2D()(x512)\n",
        "    x1 = Conv2D(1, (4, 4), strides=1, padding='valid', activation='sigmoid', kernel_initializer=init)(padded_x512)\n",
        "\n",
        "    model = Model(inputs=[input_gen, input_tar], outputs=x1)\n",
        "    return model\n",
        "\n",
        "discriminatotr=create_patchgan((128, 128, 3))\n",
        "discriminatotr.summary()"
      ],
      "metadata": {
        "id": "2081niw1YG1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mod_unet():\n",
        "    input_src = Input(shape=(128, 128, 3))\n",
        "\n",
        "    x64 = d_block(input_src, 64, 2, 'same', False, False)\n",
        "    x128 = d_block(x64, 128, 2, 'same', True, False)\n",
        "    x256 = d_block(x128, 256, 2, 'same', True, False)\n",
        "    x512 = d_block(x256, 512, 2, 'same', True, False)\n",
        "    d512 = d_block(x512, 512, 2, 'same', True, False)\n",
        "    e512 = d_block(d512, 512, 2, 'same', True, False)\n",
        "\n",
        "    f512 = d_block(e512, 512, 2, 'same', True, False)\n",
        "\n",
        "    u512 = u_block(f512, e512, 512, 2, 'same', True, False)\n",
        "    u512 = u_block(u512, d512, 512, 2, 'same', True, False)\n",
        "    u512 = u_block(u512, x512, 512, 2, 'same', True, False)\n",
        "    u256 = u_block(u512, x256, 256, 2, 'same', True, False)\n",
        "    u128 = u_block(u256, x128, 128, 2, 'same', True, False)\n",
        "    u64 = u_block(u128, x64, 64, 2, 'same', False, True)\n",
        "\n",
        "    generated_image = Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh', kernel_initializer=init)(u64)\n",
        "\n",
        "    model = Model(inputs=input_src, outputs=generated_image)\n",
        "    return model\n",
        "\n",
        "\n",
        "generator = create_mod_unet()\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "id": "faRJNjw0YNIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "valid = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
        "\n",
        "train = train.shuffle(buffer_size=400).batch(batch_size=16)\n",
        "valid = valid.shuffle(buffer_size=400).batch(batch_size=16)\n",
        "\n",
        "gen_model = create_mod_unet()\n",
        "dis_models = [create_patchgan((128, 128, 3)), create_patchgan((64, 64, 3)), create_patchgan((32, 32, 3))]\n",
        "\n",
        "LAMBDA=100\n",
        "optimizer_params = { \"learning_rate\": 0.0002,\"beta_1\": 0.5,\"beta_2\": 0.999}\n",
        "\n",
        "gen_opt = tf.keras.optimizers.Adam(**optimizer_params)\n",
        "dis_opt_0 = tf.keras.optimizers.Adam(**optimizer_params)\n",
        "dis_opt_1 = tf.keras.optimizers.Adam(**optimizer_params)\n",
        "dis_opt_2 = tf.keras.optimizers.Adam(**optimizer_params)\n",
        "\n",
        "bce_loss = keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "C3qHC9xFYSZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_loss(dis_gen_out, target_img, gen_img):\n",
        "    adv_loss = bce_loss(tf.ones_like(dis_gen_out), dis_gen_out)\n",
        "    l1_loss = tf.reduce_mean(tf.abs(tf.subtract(target_img, gen_img)))\n",
        "    total_loss = adv_loss + (LAMBDA * l1_loss)\n",
        "    return total_loss, adv_loss, l1_loss\n",
        "\n",
        "def dis_loss(dis_gen_out, dis_target_out):\n",
        "    gen_loss = bce_loss(tf.zeros_like(dis_gen_out), dis_gen_out)\n",
        "    target_loss = bce_loss(tf.ones_like(dis_target_out), dis_target_out)\n",
        "    total_dis_loss = gen_loss + target_loss\n",
        "    return total_dis_loss"
      ],
      "metadata": {
        "id": "6JR004xHYZi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_batch(bw_img, tar_img):\n",
        "    def resize_and_compute_losses(resized_tar_img, resized_bw_img, resized_gen_img, dis_model, dis_gen_out, tar_img, gen_img):\n",
        "        dis_out = dis_model([resized_bw_img, resized_tar_img], training=True)\n",
        "        g_loss, _, _ = gen_loss(dis_gen_out, tar_img, gen_img)\n",
        "        d_loss = dis_loss(dis_gen_out, dis_out)\n",
        "        return g_loss, d_loss\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as g:\n",
        "        gen_img = gen_model(bw_img, training=True)\n",
        "        g_losses = []\n",
        "        d_losses = []\n",
        "\n",
        "        resolutions = [(128, 128), (64, 64), (32, 32)]\n",
        "\n",
        "        for resolution, dis_model in zip(resolutions, dis_models):\n",
        "            resized_tar_img = tf.image.resize(tar_img, resolution)\n",
        "            resized_bw_img = tf.image.resize(bw_img, resolution)\n",
        "            resized_gen_img = tf.image.resize(gen_img, resolution)\n",
        "            dis_gen_out = dis_model([resized_bw_img, resized_gen_img], training=True)\n",
        "            g_loss, d_loss = resize_and_compute_losses(resized_tar_img, resized_bw_img, resized_gen_img, dis_model, dis_gen_out, tar_img, gen_img)\n",
        "            g_losses.append(g_loss)\n",
        "            d_losses.append(d_loss)\n",
        "\n",
        "        g_total_loss = sum(g_losses)\n",
        "        d_total_loss = sum(d_losses)\n",
        "\n",
        "    g_gradients = g.gradient(g_total_loss, gen_model.trainable_variables)\n",
        "    d_gradients = [g.gradient(d_loss, dis_model.trainable_variables) for d_loss, dis_model in zip(d_losses, dis_models)]\n",
        "\n",
        "    gen_opt.apply_gradients(zip(g_gradients, gen_model.trainable_variables))\n",
        "    for dis_opt, d_grad, dis_model in zip([dis_opt_0, dis_opt_1, dis_opt_2], d_gradients, dis_models):\n",
        "        dis_opt.apply_gradients(zip(d_grad, dis_model.trainable_variables))"
      ],
      "metadata": {
        "id": "VK18CNg2Ycjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(bw_img, gen_img, tar_img):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    images = [bw_img, gen_img, tar_img]\n",
        "    titles = ['Gray Scale', 'Generated', 'Ground Truth']\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.imshow((images[i][0] + 1.0) / 2.0)\n",
        "        plt.title(titles[i], fontsize=20)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for gry, clr in train.take(1) :\n",
        "    pass\n",
        "\n",
        "def fit(EPOCHS=400):\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f'Epoch {epoch} out of {EPOCHS}')\n",
        "        progress_bar = tqdm(train, total=len(train))\n",
        "\n",
        "        for bw_image, tar_image in progress_bar:\n",
        "            train_batch(bw_image, tar_image)\n",
        "\n",
        "        if epoch % 3 == 0:\n",
        "            gen_image = gen_model(gry, training=True)\n",
        "            plot_images(gry, gen_image, clr)\n",
        "fit(EPOCHS = 300)"
      ],
      "metadata": {
        "id": "kPNaGTRqYfYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_generated_images(generator, b_w_images, tar_images, num_samples=10):\n",
        "    generated_images = generator(b_w_images, training=False)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        b_w_image = (b_w_images[i] + 1.0) / 2.0\n",
        "        generated_image = (generated_images[i] + 1.0) / 2.0\n",
        "        tar_image = (tar_images[i] + 1.0) / 2.0\n",
        "\n",
        "        plt.figure(figsize=(20, 20))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(b_w_image)\n",
        "        plt.title('Gray Scale', fontsize=20)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(generated_image)\n",
        "        plt.title('Generated ', fontsize=20)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(tar_image)\n",
        "        plt.title('Grond Truth', fontsize=20)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "DoEtyc7vYkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "\n",
        "\n",
        "gen_image = gen_model(gry, training=True)\n",
        "gen_images_np = ((gen_image.numpy() + 1.0) / 2.0 * 255).astype(np.uint8)\n",
        "tar_images_np = ((clr.numpy() + 1.0) / 2.0 * 255).astype(np.uint8)\n",
        "\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "\n",
        "for gen_img, tar_img in zip(gen_images_np, tar_images_np):\n",
        "    psnr = compare_psnr(tar_img, gen_img)\n",
        "    ssim = compare_ssim(tar_img, gen_img, multichannel=True)\n",
        "    psnr_values.append(psnr)\n",
        "    ssim_values.append(ssim)\n",
        "\n",
        "average_psnr = np.mean(psnr_values)\n",
        "average_ssim = np.mean(ssim_values)\n",
        "\n",
        "print(f\"Average PSNR: {average_psnr:.2f}\")\n",
        "print(f\"Average SSIM: {average_ssim:.4f}\")\n"
      ],
      "metadata": {
        "id": "gXMrxutkYpnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_generated_images_with_metrics(generator, b_w_images, tar_images, num_samples=3):\n",
        "    generated_images = generator(b_w_images, training=False)\n",
        "\n",
        "    plt.figure(figsize=(20, 6*num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        b_w_image = (b_w_images[i] + 1.0) / 2.0\n",
        "        generated_image = (generated_images[i] + 1.0) / 2.0\n",
        "        tar_image = (tar_images[i] + 1.0) / 2.0\n",
        "\n",
        "        gen_img_np = ((generated_image.numpy() + 1.0) / 2.0 * 255).astype(np.uint8)\n",
        "        tar_img_np = ((tar_image.numpy() + 1.0) / 2.0 * 255).astype(np.uint8)\n",
        "\n",
        "        psnr = compare_psnr(tar_img_np, gen_img_np)\n",
        "        ssim = compare_ssim(tar_img_np, gen_img_np, multichannel=True)\n",
        "\n",
        "        plt.subplot(num_samples, 4, i*4 + 1)\n",
        "        plt.imshow(b_w_image)\n",
        "        plt.title('Gray Scale', fontsize=15)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 4, i*4 + 2)\n",
        "        plt.imshow(generated_image)\n",
        "        plt.title(f'Generated \\nPSNR: {psnr:.2f}\\nSSIM: {ssim:.4f}', fontsize=15)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 4, i*4 + 3)\n",
        "        plt.imshow(tar_image)\n",
        "        plt.title('Ground Truth', fontsize=15)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_generated_images_with_metrics(gen_model, gry, clr)"
      ],
      "metadata": {
        "id": "dmjVPNOOYv9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/models/chroma.h5'\n",
        "gen_model.save(model_path)"
      ],
      "metadata": {
        "id": "dzFAqEcLY1Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "generator_model_path = '/content/drive/My Drive/models/chroma.h5'\n",
        "gen0 = load_model(generator_model_path)\n",
        "\n",
        "new_image_path = '/content/baby_123.jpg'\n",
        "new_image = tf.io.read_file(new_image_path)\n",
        "new_image = tf.image.decode_jpeg(new_image, channels=3)\n",
        "new_image = tf.image.resize(new_image, (128, 128))\n",
        "new_image = tf.cast(new_image, dtype=tf.float32) / 127.5 - 1.0\n",
        "new_image = tf.expand_dims(new_image, axis=0)\n",
        "\n",
        "colorized_image = gen0(new_image, training=False)\n",
        "colorized_image = (colorized_image + 1.0) / 2.0\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(new_image[0] * 0.5 + 0.5)\n",
        "plt.title('Gray Scale')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(colorized_image[0])\n",
        "plt.title('Generated Colorized Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X0k2UAsZY4GL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}